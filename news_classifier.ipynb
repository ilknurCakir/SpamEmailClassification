{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = None, test_split = 0.2)\n",
    "word_index = reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {value:key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = X_train[0]\n",
    "news_words = [index2word[index] for index in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the wattie nondiscriminatory mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states earlier and rise and revs vs 000 its 16 vs 000 a but 3 psbr oils several and shareholders and dividend vs 000 its all 4 vs 000 1 mln agreed largely april 0 are 2 states will billion total and against 000 pct dlrs'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(news_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(map(len, X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 46)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train.shape  # 46 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words= 10000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "xtrain = tokenizer.sequences_to_matrix(X_train, mode = \"binary\")\n",
    "xtest = tokenizer.sequences_to_matrix(X_test, mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 12s 1ms/step - loss: 1.5239 - acc: 0.6655 - val_loss: 1.0971 - val_acc: 0.7642\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 12s 2ms/step - loss: 0.6809 - acc: 0.8450 - val_loss: 0.9421 - val_acc: 0.8009\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 13s 2ms/step - loss: 0.3769 - acc: 0.9110 - val_loss: 0.9370 - val_acc: 0.7953\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 15s 2ms/step - loss: 0.2563 - acc: 0.9384 - val_loss: 0.9931 - val_acc: 0.8053\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.1937 - acc: 0.9516 - val_loss: 1.0482 - val_acc: 0.7976\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.1824 - acc: 0.9510 - val_loss: 1.0078 - val_acc: 0.8009\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.1606 - acc: 0.9537 - val_loss: 1.0782 - val_acc: 0.8042\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.1418 - acc: 0.9577 - val_loss: 1.1278 - val_acc: 0.7987\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.1436 - acc: 0.9555 - val_loss: 1.0838 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 18s 2ms/step - loss: 0.1304 - acc: 0.9576 - val_loss: 1.1759 - val_acc: 0.7942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8b12e4630>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_shape= xtrain.shape[1:], activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(46, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(xtrain, y_cat_train,\n",
    "         batch_size = 32,\n",
    "         validation_split = 0.1, \n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 19s 2ms/step - loss: 1.5091 - acc: 0.6772 - val_loss: 1.1295 - val_acc: 0.7508\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 18s 2ms/step - loss: 0.7209 - acc: 0.8330 - val_loss: 0.9374 - val_acc: 0.7953\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.4295 - acc: 0.9020 - val_loss: 0.8918 - val_acc: 0.8187\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 18s 2ms/step - loss: 0.2948 - acc: 0.9308 - val_loss: 1.0260 - val_acc: 0.8076\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 20s 2ms/step - loss: 0.2427 - acc: 0.9398 - val_loss: 1.0495 - val_acc: 0.8098\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 20s 3ms/step - loss: 0.2001 - acc: 0.9505 - val_loss: 1.0559 - val_acc: 0.8109\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 20s 2ms/step - loss: 0.1906 - acc: 0.9506 - val_loss: 1.0983 - val_acc: 0.8131\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 20s 2ms/step - loss: 0.1716 - acc: 0.9526 - val_loss: 1.1461 - val_acc: 0.8076\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 20s 2ms/step - loss: 0.1652 - acc: 0.9537 - val_loss: 1.1088 - val_acc: 0.8109\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 20s 3ms/step - loss: 0.1498 - acc: 0.9571 - val_loss: 1.1949 - val_acc: 0.8087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8b0ca3278>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words= 10000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "xtrain = tokenizer.sequences_to_matrix(X_train, mode = \"count\")\n",
    "xtest = tokenizer.sequences_to_matrix(X_test, mode = \"count\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_shape= xtrain.shape[1:], activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(46, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(xtrain, y_cat_train,\n",
    "         batch_size = 32,\n",
    "         validation_split = 0.1, \n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 1.4059 - acc: 0.6937 - val_loss: 1.0655 - val_acc: 0.7786\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.6646 - acc: 0.8538 - val_loss: 0.9870 - val_acc: 0.8131\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.4349 - acc: 0.9057 - val_loss: 1.0775 - val_acc: 0.8098\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.3442 - acc: 0.9240 - val_loss: 1.1566 - val_acc: 0.8109\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 22s 3ms/step - loss: 0.2955 - acc: 0.9350 - val_loss: 1.1171 - val_acc: 0.8053\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 22s 3ms/step - loss: 0.2724 - acc: 0.9416 - val_loss: 1.2033 - val_acc: 0.8020\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 22s 3ms/step - loss: 0.2500 - acc: 0.9469 - val_loss: 1.2682 - val_acc: 0.7953: 0.2508 \n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.2456 - acc: 0.9472 - val_loss: 1.1651 - val_acc: 0.8142\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.2252 - acc: 0.9495 - val_loss: 1.2038 - val_acc: 0.8109\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.2013 - acc: 0.9501 - val_loss: 1.2303 - val_acc: 0.7953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8b08c17f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words= 10000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "\n",
    "tokenizer.fit_on_sequences(xtrain)\n",
    "xtrain = tokenizer.sequences_to_matrix(X_train, mode = \"tfidf\")\n",
    "xtest = tokenizer.sequences_to_matrix(X_test, mode = \"tfidf\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_shape= xtrain.shape[1:], activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(46, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(xtrain, y_cat_train,\n",
    "         batch_size = 32,\n",
    "         validation_split = 0.1, \n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 23s 3ms/step - loss: 2.2497 - acc: 0.4472 - val_loss: 1.8060 - val_acc: 0.5250\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 19s 2ms/step - loss: 1.6268 - acc: 0.5778 - val_loss: 1.5645 - val_acc: 0.6363\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 19s 2ms/step - loss: 1.3807 - acc: 0.6682 - val_loss: 1.3464 - val_acc: 0.6897\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 19s 2ms/step - loss: 1.1538 - acc: 0.7171 - val_loss: 1.1990 - val_acc: 0.7253\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 19s 2ms/step - loss: 0.9931 - acc: 0.7486 - val_loss: 1.1200 - val_acc: 0.7453\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 20s 2ms/step - loss: 0.8749 - acc: 0.7792 - val_loss: 1.0759 - val_acc: 0.7642\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 22s 3ms/step - loss: 0.7643 - acc: 0.8059 - val_loss: 1.0544 - val_acc: 0.7586\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.6847 - acc: 0.8210 - val_loss: 1.0336 - val_acc: 0.7653\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.6060 - acc: 0.8367 - val_loss: 1.0301 - val_acc: 0.7686\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 21s 3ms/step - loss: 0.5278 - acc: 0.8570 - val_loss: 1.0527 - val_acc: 0.7653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8e8ed4358>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words= 10000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "\n",
    "xtrain = tokenizer.sequences_to_matrix(X_train, mode = \"freq\")\n",
    "xtest = tokenizer.sequences_to_matrix(X_test, mode = \"freq\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_shape= xtrain.shape[1:], activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(46, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(xtrain, y_cat_train,\n",
    "         batch_size = 32,\n",
    "         validation_split = 0.1, \n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
